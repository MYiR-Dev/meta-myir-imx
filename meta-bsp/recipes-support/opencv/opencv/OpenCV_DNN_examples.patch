From 3c4daafb54f961e376104a461ca7ec114ff0331a Mon Sep 17 00:00:00 2001
From: Ludek Slosarcik <ludek.slosarcik@nxp.com>
Date: Fri, 14 Feb 2020 15:46:50 +0100
Subject: [PATCH] opencv_dnn: added video device for 2 examples, and change text labels

Signed-off-by: Ludek Slosarcik <ludek.slosarcik@nxp.com>

Upstream-Status: Pending
---
 samples/cpp/logistic_regression.cpp |  2 +-
 samples/dnn/classification.cpp      |  7 ++++---
 samples/dnn/object_detection.cpp    | 10 +++++-----
 samples/dnn/segmentation.cpp        |  2 +-
 samples/dnn/text_detection.cpp      |  5 +++--
 5 files changed, 14 insertions(+), 12 deletions(-)

diff --git a/samples/cpp/logistic_regression.cpp b/samples/cpp/logistic_regression.cpp
index 365b32e523..5dca6b3835 100644
--- a/samples/cpp/logistic_regression.cpp
+++ b/samples/cpp/logistic_regression.cpp
@@ -83,7 +83,7 @@ static float calculateAccuracyPercent(const Mat &original, const Mat &predicted)
 
 int main()
 {
-    const String filename = samples::findFile("data01.xml");
+    const String filename = samples::findFile("../data/data01.xml");
     cout << "**********************************************************************" << endl;
     cout << filename
          << " contains digits 0 and 1 of 20 samples each, collected on an Android device" << endl;
diff --git a/samples/dnn/classification.cpp b/samples/dnn/classification.cpp
index 0ae9e6ed94..0a290a8f33 100644
--- a/samples/dnn/classification.cpp
+++ b/samples/dnn/classification.cpp
@@ -11,6 +11,7 @@ std::string keys =
     "{ help  h     | | Print help message. }"
     "{ @alias      | | An alias name of model to extract preprocessing parameters from models.yml file. }"
     "{ zoo         | models.yml | An optional path to file with preprocessing parameters }"
+    "{ device      |  0 | camera device number. }"
     "{ input i     | | Path to input image or video file. Skip this argument to capture frames from a camera.}"
     "{ framework f | | Optional name of an origin framework of the model. Detect it automatically if it does not set. }"
     "{ classes     | | Optional path to a text file with names of classes. }"
@@ -94,7 +95,7 @@ int main(int argc, char** argv)
     if (parser.has("input"))
         cap.open(parser.get<String>("input"));
     else
-        cap.open(0);
+        cap.open(parser.get<int>("device"));
     //! [Open a video file or an image file or a camera stream]
 
     // Process frames.
@@ -131,13 +132,13 @@ int main(int argc, char** argv)
         double freq = getTickFrequency() / 1000;
         double t = net.getPerfProfile(layersTimes) / freq;
         std::string label = format("Inference time: %.2f ms", t);
-        putText(frame, label, Point(0, 15), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 255, 0));
+        putText(frame, label, Point(0, 20), FONT_HERSHEY_SIMPLEX, 0.8, Scalar(0, 0, 255), 2, 8, false);
 
         // Print predicted class.
         label = format("%s: %.4f", (classes.empty() ? format("Class #%d", classId).c_str() :
                                                       classes[classId].c_str()),
                                    confidence);
-        putText(frame, label, Point(0, 40), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 255, 0));
+        putText(frame, label, Point(0, 45), FONT_HERSHEY_SIMPLEX, 0.8, Scalar(0, 0, 255), 2, 8, false);
 
         imshow(kWinName, frame);
     }
diff --git a/samples/dnn/object_detection.cpp b/samples/dnn/object_detection.cpp
index 83ed10db5d..6fa8e08ad8 100644
--- a/samples/dnn/object_detection.cpp
+++ b/samples/dnn/object_detection.cpp
@@ -250,13 +250,13 @@ int main(int argc, char** argv)
         if (predictionsQueue.counter > 1)
         {
             std::string label = format("Camera: %.2f FPS", framesQueue.getFPS());
-            putText(frame, label, Point(0, 15), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 255, 0));
+            putText(frame, label, Point(0, 20), FONT_HERSHEY_SIMPLEX, 0.8, Scalar(0, 0, 255), 2, 8, false);
 
             label = format("Network: %.2f FPS", predictionsQueue.getFPS());
-            putText(frame, label, Point(0, 30), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 255, 0));
+            putText(frame, label, Point(0, 45), FONT_HERSHEY_SIMPLEX, 0.8, Scalar(0, 0, 255), 2, 8, false);
 
             label = format("Skipped frames: %d", framesQueue.counter - predictionsQueue.counter);
-            putText(frame, label, Point(0, 45), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 255, 0));
+            putText(frame, label, Point(0, 70), FONT_HERSHEY_SIMPLEX, 0.8, Scalar(0, 0, 255), 2, 8, false);
         }
         imshow(kWinName, frame);
     }
@@ -292,7 +292,7 @@ int main(int argc, char** argv)
         double freq = getTickFrequency() / 1000;
         double t = net.getPerfProfile(layersTimes) / freq;
         std::string label = format("Inference time: %.2f ms", t);
-        putText(frame, label, Point(0, 15), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 255, 0));
+        putText(frame, label, Point(0, 20), FONT_HERSHEY_SIMPLEX, 0.8, Scalar(0, 0, 255), 2, 8, false);
 
         imshow(kWinName, frame);
     }
@@ -424,7 +424,7 @@ void drawPred(int classId, float conf, int left, int top, int right, int bottom,
     top = max(top, labelSize.height);
     rectangle(frame, Point(left, top - labelSize.height),
               Point(left + labelSize.width, top + baseLine), Scalar::all(255), FILLED);
-    putText(frame, label, Point(left, top), FONT_HERSHEY_SIMPLEX, 0.5, Scalar());
+    putText(frame, label, Point(left, top), FONT_HERSHEY_SIMPLEX, 0.8, Scalar());
 }
 
 void callback(int pos, void*)
diff --git a/samples/dnn/segmentation.cpp b/samples/dnn/segmentation.cpp
index d9fbad8974..2e0c6908d5 100644
--- a/samples/dnn/segmentation.cpp
+++ b/samples/dnn/segmentation.cpp
@@ -157,7 +157,7 @@ int main(int argc, char** argv)
         double freq = getTickFrequency() / 1000;
         double t = net.getPerfProfile(layersTimes) / freq;
         std::string label = format("Inference time: %.2f ms", t);
-        putText(frame, label, Point(0, 15), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 255, 0));
+        putText(frame, label, Point(0, 20), FONT_HERSHEY_SIMPLEX, 0.8, Scalar(0, 0, 255), 2, 8, false);
 
         imshow(kWinName, frame);
         if (!classes.empty())
diff --git a/samples/dnn/text_detection.cpp b/samples/dnn/text_detection.cpp
index e7b0f237d3..00cd22e144 100644
--- a/samples/dnn/text_detection.cpp
+++ b/samples/dnn/text_detection.cpp
@@ -8,6 +8,7 @@ using namespace cv::dnn;
 const char* keys =
     "{ help  h     | | Print help message. }"
     "{ input i     | | Path to input image or video file. Skip this argument to capture frames from a camera.}"
+    "{ device      |  0 | camera device number. }"
     "{ model m     | | Path to a binary .pb file contains trained network.}"
     "{ width       | 320 | Preprocess input image by resizing to a specific width. It should be multiple by 32. }"
     "{ height      | 320 | Preprocess input image by resizing to a specific height. It should be multiple by 32. }"
@@ -51,7 +52,7 @@ int main(int argc, char** argv)
     if (parser.has("input"))
         cap.open(parser.get<String>("input"));
     else
-        cap.open(0);
+        cap.open(parser.get<int>("device"));
 
     static const std::string kWinName = "EAST: An Efficient and Accurate Scene Text Detector";
     namedWindow(kWinName, WINDOW_NORMAL);
@@ -109,7 +110,7 @@ int main(int argc, char** argv)
         double freq = getTickFrequency() / 1000;
         double t = net.getPerfProfile(layersTimes) / freq;
         std::string label = format("Inference time: %.2f ms", t);
-        putText(frame, label, Point(0, 15), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 255, 0));
+        putText(frame, label, Point(0, 20), FONT_HERSHEY_SIMPLEX, 0.8, Scalar(0, 0, 255), 2, 8, false);
 
         imshow(kWinName, frame);
     }
-- 
2.17.1

